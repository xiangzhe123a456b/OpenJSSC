# Video demo
https://github.com/user-attachments/assets/25a25a4b-6309-4409-b728-e7a0ab6189ee
# Abstrast
As communication systems evolve beyond simple symbol transmission, 6G networks prioritize semantic communication to improve robustness and reduce redundancy across text, speech, and images.However, existing approaches rely on static coding strategies and task-specific knowledge bases, limiting adaptability in dynamic environments.Traditional semantic communication for scene understanding encodes entire images without extracting meaningful representations,leading to inefficiencies and inconsistencies. Furthermore,sender-receiver knowledge misalignment due to localized knowledge bases hinders accurate semantic interpretation.To overcome these challenges, we introduce Open Joint Source-Channel Coding (OpenJSCC)â€”a novel framework 
that integrates structured semantic representations with task aware knowledge base construction. Unlike conventional methods that focus on low-level feature encoding, Open-JSCC leverages large language models (LLMs) and scene graph generation to capture object relationships and contex-tual semantics, enhancing visual-textual reasoning in tasks like visual question answering (VQA). Experimental results demonstrate that OpenJSCC enhances both transmission efficiency and semantic accuracy, outperforming existing communication methods in VQA tasks across simulated and real-world environments.
# Introduction
<img src="![figure 4](https://github.com/user-attachments/assets/74b2c32f-b95f-4b2b-aa53-8f4a85514dd5)" width="210px">
# Framework
![figure2 (1)](https://github.com/user-attachments/assets/bf28610e-4f8d-4766-b496-5a35288423f7)
# Experiment
![9e91f058edfe4fb3a9374d527d3bd0f](https://github.com/user-attachments/assets/2d4a4871-fab8-4726-8d94-84eb1f70969c)
![7b62b41955f1dfadcaf20fc5c53de60](https://github.com/user-attachments/assets/618ab6e3-4c34-48b9-be29-fde18da887ab)
![0034213cb35bded50181dcfa534cedc](https://github.com/user-attachments/assets/0425d5f4-5b5b-498a-85c5-d829c5c7a693)

